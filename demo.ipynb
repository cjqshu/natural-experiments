{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rtealwitter/naturalexperiments/blob/main/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgJYLUyx7d24"
      },
      "source": [
        "# naturalexperiments\n",
        "\n",
        "The `naturalexperiments` package is a comprehensive toolbox for treatment effect estimation. The package includes a variety of datasets, estimators, and evaluation metrics for treatment effect estimation. The package is designed to be accessible to researchers and practitioners who are new to treatment effect estimation and to provide a comprehensive set of tools for experienced researchers.\n",
        "\n",
        "For faster (but still not fast) evaluation, we suggest selecting a GPU runtime if using Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aiz59HGT5g-s"
      },
      "outputs": [],
      "source": [
        "!pip install naturalexperiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0HB1bMVX5mtm"
      },
      "outputs": [],
      "source": [
        "import naturalexperiments as ne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvo_QVcF6Xxb"
      },
      "source": [
        "## Datasets\n",
        "\n",
        "We introduce a novel treatment effect dataset from an early childhood literacy natural experiment. The treatment in the experiment is participation in Reach Out and Read Colorado (RORCO). The dataset has an observational version called RORCO Real with real literacy outcomes and a semi-synthetic version called RORCO for estimator evaluation purposes.\n",
        "\n",
        "In addition to RORCO and RORCO Real, we provide easy access to standard treatment effect datasets including ACIC 2016, ACIC 2017, IHDP, Jobs, News, and Twins.\n",
        "\n",
        "All of the datasets can be loaded using the `dataloaders` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mRCUVTVJ6O_K"
      },
      "outputs": [],
      "source": [
        "dataset = 'RORCO'\n",
        "\n",
        "X, y, z = ne.dataloaders[dataset]()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlRrU_Qo6aVM"
      },
      "source": [
        "## Estimators\n",
        "\n",
        "We propose a novel, theoretically motivated doubly robust estimator called Double-Double. In addition to Double-Double, we provide implementations of more than 20 established estimators from the literature.\n",
        "\n",
        "All of the estimators can be easily loaded using the `methods` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Kzw5TEHb6iBn"
      },
      "outputs": [],
      "source": [
        "method = 'Double-Double'\n",
        "estimator = ne.methods[method]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can check the other estimators by inspecting the keys of `methods`."
      ],
      "metadata": {
        "id": "G_4ghDcjM0hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(ne.methods.keys()))"
      ],
      "metadata": {
        "id": "bmVWoYcsM46Y",
        "outputId": "d5f2d92d-497a-4e01-a589-8015258dda00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Regression Discontinuity', 'Propensity Stratification', 'Direct Difference', 'Adjusted Direct', 'Horvitz-Thompson', 'TMLE', 'Off-policy', 'Double-Double', 'Doubly Robust', 'Direct Prediction', 'SNet', 'FlexTENet', 'OffsetNet', 'TNet', 'TARNet', 'DragonNet', 'SNet3', 'DRNet', 'RANet', 'PWNet', 'RNet', 'XNet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuI8-U2H6mVJ"
      },
      "source": [
        "Each method takes the following arguments: the covariates `X`, the outcomes `y`, the treatment assignment `z`, propensity score estimates `p`, and a function for training `train` predictions in the estimator.\n",
        "\n",
        "We can use the `estimate_propensity` function to estimate the propensity scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lJPo4Flh6mwQ"
      },
      "outputs": [],
      "source": [
        "p = ne.estimate_propensity(X, z) # Roughly 1 minute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgFyOAm76olM"
      },
      "source": [
        "Then, with the propensity scores, we can estimate the treatment effects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nQfnVNmG6u0p"
      },
      "outputs": [],
      "source": [
        "estimated_effect = estimator(X, y, z, p, ne.train) # Roughly 1 minute"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_effect = (y['y1'] - y['y0']).mean()\n",
        "print(f'The treatment effect is {true_effect} while the treatment effect estimated by {method} is {estimated_effect}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDY5xcrxKfn3",
        "outputId": "b5ebfec5-fa67-4096-e842-ecd7cf28f43c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The treatment effect is 0.08955221295798275 while the treatment effect estimated by Double-Double is 0.08833388528237851.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr3yVv2p6rqC"
      },
      "source": [
        "By default, `train` trains a three-layer neural network with 100 units in each layer and ReLU activations.\n",
        "Some estimators, such as regression discontinuity, do not use the training functions and some estimators, such as the CATENet estimators, use custom training functions defined in the estimator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olnU6nUN6kML"
      },
      "source": [
        "## Exploring the Datasets\n",
        "\n",
        "We can explore the datasets with a tabular comparison and several figures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lO61n1I66_m",
        "outputId": "8de96188-ba2f-4bca-a125-9be12da2d695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ACIC data...\n",
            "Downloading IHDP data...\n",
            "Downloading Jobs data...\n",
            "Downloading News data...\n",
            "Downloading twins data...\n",
            "Dataset       Size    Variables    % Treated    Cross Entropy    Corr(y1, p)    Corr(y0, p)\n",
            "----------  ------  -----------  -----------  ---------------  -------------  -------------\n",
            "ACIC 2016     4802           54         18.4           0.379         0.129         0.0393\n",
            "ACIC 2017     4302           50         51             0.606        -0.116        -0.0247\n",
            "IHDP           747           26         18.6           0.459         0.0785        0.0199\n",
            "JOBS           722            8         41.1           0.0827        0.0356        0.0766\n",
            "NEWS          5000            3         45.8           0.545         0.858        -0.563\n",
            "TWINS        50820           40         49             0.506         0.00133      -0.000665\n",
            "RORCO Real    4178           78         25.3           0.162        -0.027        -0.101\n",
            "RORCO        21663           78         49.4           0.151        -0.979        -0.98\n"
          ]
        }
      ],
      "source": [
        "# Produces a markdown table comparing the size, number of variables, treatment rate, etc.\n",
        "ne.dataset_table(ne.dataloaders, print_md=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaZ0EiCO65q-"
      },
      "source": [
        "## Benchmarking the Estimators\n",
        "\n",
        "We can benchmark the estimators on the datasets using the `compute_variance` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "G07z-m4X7ALp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b379adcd-d876-4f1a-80bc-93c3dacb9edb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [03:50<00:00, 46.03s/it]\n"
          ]
        }
      ],
      "source": [
        "methods = {name: ne.methods[name] for name in ['Double-Double', 'Regression Discontinuity', 'DragonNet']}\n",
        "\n",
        "variance, times = ne.compute_variance(methods, dataset, num_runs=5) # Roughly 1 minute per run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MAuvybp7Ca2"
      },
      "source": [
        "Due to the computational complexity of some estimators (e..g, the CATENets), the benchmark subsamples the data by default. We can adjust the subsample size with the `limit` argument. Even then, many estimators may take a long time to run.\n",
        "\n",
        "Once we benchmark the estimators, we can print the results in a table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6nsSsUW_7E8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ba1387-e6d5-4eef-ea94-86cfbff7e8b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Method                   |     Mean |   1st Quartile |   2nd Quartile |   3rd Quartile |   Time (s) |\n",
            "|--------------------------|----------|----------------|----------------|----------------|------------|\n",
            "| Double-Double            | 1.04e-05 |       8.18e-06 |       1.01e-05 |       1.38e-05 |   27.6     |\n",
            "| Regression Discontinuity | 0.00467  |       0.00411  |       0.00493  |       0.00588  |    0.00115 |\n",
            "| TARNet                   | 2.72e-05 |       2.72e-05 |       2.72e-05 |       2.72e-05 |   99.2     |\n",
            "| DragonNet                | 0.0223   |       0.0217   |       0.0227   |       0.0252   |    4.62    |\n"
          ]
        }
      ],
      "source": [
        "ne.benchmark_table(variance, times, print_md=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHokXyTh7Hrk"
      },
      "source": [
        "## Additional Features\n",
        "\n",
        "The `naturalexperiments` package includes additional features for comprehensively evaluating treatment effect estimation.\n",
        "\n",
        "There are functions for computing the empirical variance as a function of the sample size, the correlation in the outcomes, and the propensity score accuracy.\n",
        "\n",
        "These functions and more appear in the `paper_experiments` folder (as the name suggests, the folder includes code to reproduce the results in the paper). Because some experiments are computationally intensive, the functions are designed to run in parallel by writing the results to a shared cache."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}