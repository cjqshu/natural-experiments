{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgJYLUyx7d24"
      },
      "source": [
        "# naturalexperiments\n",
        "\n",
        "The `naturalexperiments` package is a comprehensive toolbox for treatment effect estimation. The package includes a variety of datasets, estimators, and evaluation metrics for treatment effect estimation. The package is designed to be accessible to researchers and practitioners who are new to treatment effect estimation and to provide a comprehensive set of tools for experienced researchers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aiz59HGT5g-s",
        "outputId": "996a0b11-a85f-4b4f-d732-d28032e3705d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting naturalexperiments\n",
            "  Downloading naturalexperiments-0.2.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: torch in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from naturalexperiments) (2.3.1)\n",
            "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from naturalexperiments) (1.26.4)\n",
            "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from naturalexperiments) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from naturalexperiments) (1.5.0)\n",
            "Requirement already satisfied: scipy in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from naturalexperiments) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from naturalexperiments) (3.9.0)\n",
            "Collecting geopandas (from naturalexperiments)\n",
            "  Downloading geopandas-0.14.4-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting geopy (from naturalexperiments)\n",
            "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting contextily (from naturalexperiments)\n",
            "  Downloading contextily-1.6.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from naturalexperiments) (4.66.4)\n",
            "Collecting catenets (from naturalexperiments)\n",
            "  Downloading catenets-0.2.3-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: tabulate in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from naturalexperiments) (0.9.0)\n",
            "Collecting rdata (from naturalexperiments)\n",
            "  Downloading rdata-0.11.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting gdown (from catenets->naturalexperiments)\n",
            "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jax>=0.3.16 (from catenets->naturalexperiments)\n",
            "  Downloading jax-0.4.28-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting loguru>=0.5.3 (from catenets->naturalexperiments)\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting pytest>=6.2.4 (from catenets->naturalexperiments)\n",
            "  Downloading pytest-8.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from catenets->naturalexperiments) (2.32.3)\n",
            "Collecting jaxlib>=0.3.14 (from catenets->naturalexperiments)\n",
            "  Downloading jaxlib-0.4.28-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from pandas->naturalexperiments) (2.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from pandas->naturalexperiments) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from pandas->naturalexperiments) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from scikit-learn->naturalexperiments) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from scikit-learn->naturalexperiments) (3.5.0)\n",
            "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from torch->naturalexperiments) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from torch->naturalexperiments) (4.12.1)\n",
            "Requirement already satisfied: sympy in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from torch->naturalexperiments) (1.12.1)\n",
            "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from torch->naturalexperiments) (3.3)\n",
            "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from torch->naturalexperiments) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from torch->naturalexperiments) (2024.6.0)\n",
            "Collecting mercantile (from contextily->naturalexperiments)\n",
            "  Downloading mercantile-1.2.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: pillow in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from contextily->naturalexperiments) (10.3.0)\n",
            "Collecting rasterio (from contextily->naturalexperiments)\n",
            "  Downloading rasterio-1.3.10-cp312-cp312-macosx_11_0_arm64.whl.metadata (14 kB)\n",
            "Collecting xyzservices (from contextily->naturalexperiments)\n",
            "  Downloading xyzservices-2024.6.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting fiona>=1.8.21 (from geopandas->naturalexperiments)\n",
            "  Downloading fiona-1.9.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from geopandas->naturalexperiments) (24.0)\n",
            "Collecting pyproj>=3.3.0 (from geopandas->naturalexperiments)\n",
            "  Downloading pyproj-3.6.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (31 kB)\n",
            "Collecting shapely>=1.8.0 (from geopandas->naturalexperiments)\n",
            "  Downloading shapely-2.0.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
            "Collecting geographiclib<3,>=1.52 (from geopy->naturalexperiments)\n",
            "  Downloading geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from matplotlib->naturalexperiments) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from matplotlib->naturalexperiments) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from matplotlib->naturalexperiments) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from matplotlib->naturalexperiments) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from matplotlib->naturalexperiments) (3.1.2)\n",
            "Collecting xarray (from rdata->naturalexperiments)\n",
            "  Downloading xarray-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting attrs>=19.2.0 (from fiona>=1.8.21->geopandas->naturalexperiments)\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from fiona>=1.8.21->geopandas->naturalexperiments) (2024.6.2)\n",
            "Collecting click~=8.0 (from fiona>=1.8.21->geopandas->naturalexperiments)\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting click-plugins>=1.0 (from fiona>=1.8.21->geopandas->naturalexperiments)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting cligj>=0.5 (from fiona>=1.8.21->geopandas->naturalexperiments)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: six in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from fiona>=1.8.21->geopandas->naturalexperiments) (1.16.0)\n",
            "Collecting ml-dtypes>=0.2.0 (from jax>=0.3.16->catenets->naturalexperiments)\n",
            "  Downloading ml_dtypes-0.4.0-cp312-cp312-macosx_10_9_universal2.whl.metadata (20 kB)\n",
            "Collecting opt-einsum (from jax>=0.3.16->catenets->naturalexperiments)\n",
            "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting iniconfig (from pytest>=6.2.4->catenets->naturalexperiments)\n",
            "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting pluggy<2.0,>=1.5 (from pytest>=6.2.4->catenets->naturalexperiments)\n",
            "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting beautifulsoup4 (from gdown->catenets->naturalexperiments)\n",
            "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from jinja2->torch->naturalexperiments) (2.1.5)\n",
            "Collecting affine (from rasterio->contextily->naturalexperiments)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting snuggs>=1.4.1 (from rasterio->contextily->naturalexperiments)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from rasterio->contextily->naturalexperiments) (69.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from requests->catenets->naturalexperiments) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from requests->catenets->naturalexperiments) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from requests->catenets->naturalexperiments) (2.2.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages (from sympy->torch->naturalexperiments) (1.3.0)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4->gdown->catenets->naturalexperiments)\n",
            "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown->catenets->naturalexperiments)\n",
            "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading naturalexperiments-0.2.1-py3-none-any.whl (30 kB)\n",
            "Downloading catenets-0.2.3-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contextily-1.6.0-py3-none-any.whl (17 kB)\n",
            "Downloading geopandas-0.14.4-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdata-0.11.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fiona-1.9.6-cp312-cp312-macosx_11_0_arm64.whl (13.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax-0.4.28-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.4.28-cp312-cp312-macosx_11_0_arm64.whl (64.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproj-3.6.1-cp312-cp312-macosx_11_0_arm64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pytest-8.2.2-py3-none-any.whl (339 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m339.9/339.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shapely-2.0.4-cp312-cp312-macosx_11_0_arm64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
            "Downloading mercantile-1.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading rasterio-1.3.10-cp312-cp312-macosx_11_0_arm64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading xarray-2024.5.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xyzservices-2024.6.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading ml_dtypes-0.4.0-cp312-cp312-macosx_10_9_universal2.whl (394 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.4/394.4 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
            "Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
            "Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
            "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: xyzservices, soupsieve, snuggs, shapely, PySocks, pyproj, pluggy, opt-einsum, ml-dtypes, loguru, iniconfig, geographiclib, click, attrs, affine, pytest, mercantile, jaxlib, jax, geopy, cligj, click-plugins, beautifulsoup4, xarray, rasterio, gdown, fiona, rdata, geopandas, contextily, catenets, naturalexperiments\n",
            "Successfully installed PySocks-1.7.1 affine-2.4.0 attrs-23.2.0 beautifulsoup4-4.12.3 catenets-0.2.3 click-8.1.7 click-plugins-1.1.1 cligj-0.7.2 contextily-1.6.0 fiona-1.9.6 gdown-5.2.0 geographiclib-2.0 geopandas-0.14.4 geopy-2.4.1 iniconfig-2.0.0 jax-0.4.28 jaxlib-0.4.28 loguru-0.7.2 mercantile-1.2.1 ml-dtypes-0.4.0 naturalexperiments-0.2.1 opt-einsum-3.3.0 pluggy-1.5.0 pyproj-3.6.1 pytest-8.2.2 rasterio-1.3.10 rdata-0.11.2 shapely-2.0.4 snuggs-1.4.7 soupsieve-2.5 xarray-2024.5.0 xyzservices-2024.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install naturalexperiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0HB1bMVX5mtm"
      },
      "outputs": [],
      "source": [
        "import naturalexperiments as ne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvo_QVcF6Xxb"
      },
      "source": [
        "## Datasets\n",
        "\n",
        "We introduce a novel treatment effect dataset from an early childhood literacy natural experiment. The treatment in the experiment is participation in Reach Out and Read Colorado (RORCO). The dataset has an observational version called RORCO Real with real literacy outcomes and a semi-synthetic version called RORCO for estimator evaluation purposes.\n",
        "\n",
        "In addition to RORCO and RORCO Real, we provide easy access to standard treatment effect datasets including ACIC 2016, ACIC 2017, IHDP, Jobs, News, and Twins.\n",
        "\n",
        "All of the datasets can be loaded using the `dataloaders` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRCUVTVJ6O_K",
        "outputId": "758c236f-cffb-4199-aef8-ac57ca145315"
      },
      "outputs": [],
      "source": [
        "dataset = 'RORCO'\n",
        "\n",
        "X, y, z = ne.dataloaders[dataset]()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlRrU_Qo6aVM"
      },
      "source": [
        "## Estimators\n",
        "\n",
        "We propose a novel, theoretically motivated doubly robust estimator called Double-Double. In addition to Double-Double, we provide implementations of more than 20 established estimators from the literature.\n",
        "\n",
        "All of the estimators can be easily loaded using the `methods` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Kzw5TEHb6iBn"
      },
      "outputs": [],
      "source": [
        "method = 'Double-Double'\n",
        "estimator = ne.methods[method]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuI8-U2H6mVJ"
      },
      "source": [
        "Each method takes the following arguments: the covariates `X`, the outcomes `y`, the treatment assignment `z`, propensity score estimates `p`, and a function for training `train` predictions in the estimator.\n",
        "\n",
        "We can use the `estimate_propensity` function to estimate the propensity scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lJPo4Flh6mwQ"
      },
      "outputs": [],
      "source": [
        "p = ne.estimate_propensity(X, z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgFyOAm76olM"
      },
      "source": [
        "Then, with the propensity scores, we can estimate the treatment effects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nQfnVNmG6u0p"
      },
      "outputs": [],
      "source": [
        "estimated_effect = estimator(X, y, z, p, ne.train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr3yVv2p6rqC"
      },
      "source": [
        "By default, `train` trains a three-layer neural network with 100 units in each layer and ReLU activations.\n",
        "Some estimators, such as regression discontinuity, do not use the training functions and some estimators, such as the CATENet estimators, use custom training functions defined in the estimator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olnU6nUN6kML"
      },
      "source": [
        "## Exploring the Datasets\n",
        "\n",
        "We can explore the datasets with a tabular comparison and several figures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ACIC 2017\n",
            "6.0 0.0\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "all elements of target should be between 0 and 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m X, y, z \u001b[38;5;241m=\u001b[39m ne\u001b[38;5;241m.\u001b[39mdataloaders[dataset]()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(z\u001b[38;5;241m.\u001b[39mmax(), z\u001b[38;5;241m.\u001b[39mmin())\n\u001b[0;32m----> 6\u001b[0m p \u001b[38;5;241m=\u001b[39m ne\u001b[38;5;241m.\u001b[39mestimate_propensity(X, z)\n\u001b[1;32m      7\u001b[0m estimated_effect \u001b[38;5;241m=\u001b[39m estimator(X, y, z, p, ne\u001b[38;5;241m.\u001b[39mtrain)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimated_effect\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/Github/naturalexperiments/naturalexperiments/model.py:94\u001b[0m, in \u001b[0;36mestimate_propensity\u001b[0;34m(X, treatment)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mestimate_propensity\u001b[39m(X, treatment):\n\u001b[0;32m---> 94\u001b[0m     propensity \u001b[38;5;241m=\u001b[39m train(X, treatment, X, is_bce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# Clip propensity to avoid numerical instability\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m propensity\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m.01\u001b[39m, \u001b[38;5;241m.99\u001b[39m)\n",
            "File \u001b[0;32m~/Github/naturalexperiments/naturalexperiments/model.py:83\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(X_train, y_train, X_test, weights, lr, epochs, return_model, clip_value, noise_multiplier, is_bce)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y, w \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     82\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(X)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m---> 83\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m loss(y, y_pred, w)\n\u001b[1;32m     84\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     85\u001b[0m     loss_value\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m~/Github/naturalexperiments/naturalexperiments/model.py:68\u001b[0m, in \u001b[0;36mtrain.<locals>.<lambda>\u001b[0;34m(y_true, y_pred, weights)\u001b[0m\n\u001b[1;32m     66\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m y_true, y_pred, weights: ((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m weights)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bce:\n\u001b[0;32m---> 68\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m y_true, y_pred, weights: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCELoss()(y_pred, y_true)\n\u001b[1;32m     70\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, output_logits\u001b[38;5;241m=\u001b[39mis_bce)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages/torch/nn/modules/loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages/torch/nn/functional.py:3154\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3151\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3152\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight, reduction_enum)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: all elements of target should be between 0 and 1"
          ]
        }
      ],
      "source": [
        "for dataset in ne.dataloaders:\n",
        "    if dataset != 'ACIC 2017': continue\n",
        "    print(dataset)\n",
        "    X, y, z = ne.dataloaders[dataset]()\n",
        "    print(z.max(), z.min())\n",
        "    p = ne.estimate_propensity(X, z)\n",
        "    estimated_effect = estimator(X, y, z, p, ne.train)\n",
        "    print(f'{dataset}: {estimated_effect}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "8lO61n1I66_m",
        "outputId": "7ba0b51e-4e32-494e-b0e7-5b978d0d089a"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "all elements of target should be between 0 and 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Produces a markdown table comparing the size, number of variables, treatment rate, etc.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ne\u001b[38;5;241m.\u001b[39mdataset_table(ne\u001b[38;5;241m.\u001b[39mdataloaders, print_md\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/Github/naturalexperiments/naturalexperiments/data_summary.py:121\u001b[0m, in \u001b[0;36mdataset_table\u001b[0;34m(dataloaders, print_md, print_latex)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataname, dataloader \u001b[38;5;129;01min\u001b[39;00m dataloaders\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    119\u001b[0m     X, y, z \u001b[38;5;241m=\u001b[39m dataloader()\n\u001b[0;32m--> 121\u001b[0m     propensity, z \u001b[38;5;241m=\u001b[39m wrap_estimate_propensity(X, z)\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m# Number of observations\u001b[39;00m\n\u001b[1;32m    124\u001b[0m     n \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m~/Github/naturalexperiments/naturalexperiments/data_summary.py:94\u001b[0m, in \u001b[0;36mwrap_estimate_propensity\u001b[0;34m(X, z)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_estimate_propensity\u001b[39m(X, z):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m z \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m         propensity \u001b[38;5;241m=\u001b[39m estimate_propensity(X, z)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m         beta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(size\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
            "File \u001b[0;32m~/Github/naturalexperiments/naturalexperiments/model.py:94\u001b[0m, in \u001b[0;36mestimate_propensity\u001b[0;34m(X, treatment)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mestimate_propensity\u001b[39m(X, treatment):\n\u001b[0;32m---> 94\u001b[0m     propensity \u001b[38;5;241m=\u001b[39m train(X, treatment, X, is_bce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# Clip propensity to avoid numerical instability\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m propensity\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m.01\u001b[39m, \u001b[38;5;241m.99\u001b[39m)\n",
            "File \u001b[0;32m~/Github/naturalexperiments/naturalexperiments/model.py:83\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(X_train, y_train, X_test, weights, lr, epochs, return_model, clip_value, noise_multiplier, is_bce)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y, w \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     82\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(X)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m---> 83\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m loss(y, y_pred, w)\n\u001b[1;32m     84\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     85\u001b[0m     loss_value\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m~/Github/naturalexperiments/naturalexperiments/model.py:68\u001b[0m, in \u001b[0;36mtrain.<locals>.<lambda>\u001b[0;34m(y_true, y_pred, weights)\u001b[0m\n\u001b[1;32m     66\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m y_true, y_pred, weights: ((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m weights)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bce:\n\u001b[0;32m---> 68\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m y_true, y_pred, weights: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCELoss()(y_pred, y_true)\n\u001b[1;32m     70\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, output_logits\u001b[38;5;241m=\u001b[39mis_bce)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages/torch/nn/modules/loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/test/lib/python3.12/site-packages/torch/nn/functional.py:3154\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3151\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3152\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight, reduction_enum)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: all elements of target should be between 0 and 1"
          ]
        }
      ],
      "source": [
        "# Produces a markdown table comparing the size, number of variables, treatment rate, etc.\n",
        "ne.dataset_table(ne.dataloaders, print_md=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Z5MVTkl1672A",
        "outputId": "62d4f498-3411-4f00-c188-d95c5c969525"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e06667a00c51>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Produces plots of the propensity score distribution, outcomes by propensity scores, and propensity calibration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/naturalexperiments/data_summary.py\u001b[0m in \u001b[0;36mplot_all_data\u001b[0;34m(dataloaders, folder)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mpropensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_estimate_propensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mplot_propensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpropensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'propensity_hist_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/naturalexperiments/data_summary.py\u001b[0m in \u001b[0;36mwrap_estimate_propensity\u001b[0;34m(X, z)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrap_estimate_propensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mpropensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_propensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/naturalexperiments/model.py\u001b[0m in \u001b[0;36mestimate_propensity\u001b[0;34m(X, treatment)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mestimate_propensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreatment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mpropensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreatment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_bce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;31m# Clip propensity to avoid numerical instability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpropensity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/naturalexperiments/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X_train, y_train, X_test, weights, lr, epochs, return_model, clip_value, noise_multiplier, is_bce)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/naturalexperiments/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, X, y, weights)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "# Produces plots of the propensity score distribution, outcomes by propensity scores, and propensity calibration\n",
        "ne.plot_all_data(ne.dataloaders)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaZ0EiCO65q-"
      },
      "source": [
        "## Benchmarking the Estimators\n",
        "\n",
        "We can benchmark the estimators on the datasets using the `compute_variance` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G07z-m4X7ALp"
      },
      "outputs": [],
      "source": [
        "methods = {name: ne.methods[name] for name in ['Double-Double', 'Regression Discontinuity', 'TARNet']}\n",
        "\n",
        "variance, times = ne.compute_variance(methods, dataset, num_runs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MAuvybp7Ca2"
      },
      "source": [
        "Due to the computational complexity of some estimators (e..g, the CATENets), the benchmark subsamples the data by default. We can adjust the subsample size with the `limit` argument. Even then, many estimators may take a long time to run.\n",
        "\n",
        "Once we benchmark the estimators, we can print the results in a table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nsSsUW_7E8l"
      },
      "outputs": [],
      "source": [
        "ne.benchmark_table(variance, times, print_md=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHokXyTh7Hrk"
      },
      "source": [
        "## Additional Features\n",
        "\n",
        "The `naturalexperiments` package includes additional features for comprehensively evaluating treatment effect estimation.\n",
        "\n",
        "There are functions for computing the empirical variance as a function of the sample size, the correlation in the outcomes, and the propensity score accuracy.\n",
        "\n",
        "These functions and more appear in the `paper_experiments` folder (as the name suggests, the folder includes code to reproduce the results in the paper). Because some experiments are computationally intensive, the functions are designed to run in parallel by writing the results to a shared cache."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
